{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml166](./images/mln166.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml167](./images/mln167.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml48](./images/mln48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml49](./images/mln49.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml50](./images/mln50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml51](./images/mln51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml52](./images/mln52.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml53](./images/mln53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml54](./images/mln54.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml72](./images/mln72.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml73](./images/mln73.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## درک نقش وزن و بایاس در یک نرون مصنوعی با استفاده از یک مثال ساده."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "فرض کنیم ورودی ما فقط یک عدد است، مثلاً دمای هوا، و ما می‌خواهیم بر اساس آن تشخیص دهیم که آیا باید کولر روشن شود یا نه."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "فرمول اصلی نرون:\n",
    "\n",
    "Output = Activation(Weight * Input + Bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 1: تعریف ورودی\n",
    "# فرض کنیم دمای هوا ورودی ما است\n",
    "input_value = 30  # دمای هوا مثلاً ۳۰ درجه سانتی‌گراد"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این مقدار همان دیتایی است که وارد نرون می‌شود. در شبکه‌های واقعی این مقدار می‌تواند پیکسل یک عکس یا یک کلمه تبدیل‌شده به عدد باشد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 2: تعریف وزن (Weight)\n",
    "# وزن مشخص می‌کند که ورودی چقدر مهم است\n",
    "weight = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگر وزن بالا باشد، یعنی ورودی اهمیت زیادی دارد. اگر صفر باشد، یعنی ورودی هیچ تأثیری در خروجی ندارد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 3: تعریف بایاس (Bias)\n",
    "# بایاس مانند یک شیفت یا تغییر دهنده در مقدار نهایی عمل می‌کند\n",
    "bias = -10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " بایاس باعث می‌شود حتی اگر ورودی صفر باشد، نرون بتواند فعال شود یا نشود. این کمک می‌کند شبکه انعطاف بیشتری داشته باشد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 4: محاسبه مجموع وزن‌دار ورودی‌ها به همراه بایاس\n",
    "# این همان بخش (Weight * Input + Bias) است\n",
    "weighted_sum = (weight * input_value) + bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " این مقدار همان چیزی است که قبل از اینکه وارد تابع فعال‌ساز شود محاسبه می‌شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 5: تعریف تابع فعال‌ساز (Activation Function)\n",
    "# ما از تابع ساده‌ی پله‌ای (step function) استفاده می‌کنیم\n",
    "\n",
    "def step_function(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع فعال‌ساز تصمیم می‌گیرد که نرون فعال شود یا نه. در این مثال اگر مقدار بیشتر از صفر باشد، خروجی ۱ می‌شود، وگرنه صفر."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neuron: 1\n"
     ]
    }
   ],
   "source": [
    "# قدم 6: محاسبه خروجی نهایی نرون\n",
    "output = step_function(weighted_sum)\n",
    "print(\"Output of the neuron:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این خروجی همان پیش‌بینی نهایی نرون ما است. اگر 1 باشد یعنی مثلاً \"کولر را روشن کن\"، اگر 0 باشد یعنی \"خاموش نگه دار\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml74](./images/mln74.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml75](./images/mln75.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml76](./images/mln76.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "Forward Propagation چیست؟\n",
    "\n",
    "فرآیندی است که در آن داده‌های ورودی وارد شبکه عصبی شده و از لایه‌های مختلف عبور می‌کنند تا خروجی تولید شود.\n",
    "\n",
    "در این مسیر:\n",
    "\n",
    "   در هر نرون، ورودی‌ها ضرب در وزن‌ها می‌شوند،\n",
    "\n",
    "   بایاس اضافه می‌شود،\n",
    "\n",
    "   نتیجه از یک تابع فعال‌ساز عبور داده می‌شود (مثل ReLU یا سیگموید)،\n",
    "\n",
    "   و در نهایت خروجی پیش‌بینی می‌شود."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## مثال\n",
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "\n",
    "مدلسازی یک شبکه عصبی بسیار ساده با:\n",
    "\n",
    "   یک لایه ورودی\n",
    "\n",
    "   یک لایه پنهان (با ۲ نرون)\n",
    "\n",
    "   یک لایه خروجی\n",
    "\n",
    "برای پیش‌بینی یک مقدار خروجی با استفاده از Forward Propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 1: تعریف ورودی‌ها (Input Layer)\n",
    "# فرض کنید ورودی ما دو ویژگی دارد: مثلا قد و وزن\n",
    "inputs = [1.5, 2.0]  # این‌ها همان داده‌های ورودی هستند\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در اینجا، 1.5 و 2.0 به عنوان ویژگی‌هایی از یک نمونه ورودی در نظر گرفته شوند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 2: وزن‌ها و بایاس‌ها برای لایه پنهان (Hidden Layer)\n",
    "\n",
    "# وزن‌ها برای دو نرون در لایه پنهان\n",
    "weights_hidden = [\n",
    "    [0.1, 0.2],   # وزن‌های نرون اول برای دو ورودی\n",
    "    [0.4, 0.3]    # وزن‌های نرون دوم برای دو ورودی\n",
    "]\n",
    "\n",
    "# بایاس‌ها برای هر نرون در لایه پنهان\n",
    "bias_hidden = [0.1, -0.1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " هر نرون در لایه پنهان، دو ورودی دارد و وزن مخصوص به خودش برای هر ورودی."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 3: تعریف تابع فعال‌ساز (Activation Function)\n",
    "# از تابع سیگموید استفاده می‌کنیم برای غیرخطی‌سازی\n",
    "\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع فعال‌ساز باعث می‌شود که شبکه بتواند روابط غیرخطی را یاد بگیرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 4: محاسبه خروجی نرون‌های لایه پنهان (Forward Propagation - Hidden Layer)\n",
    "hidden_outputs = []\n",
    "\n",
    "for i in range(2):  # دو نرون در لایه پنهان داریم\n",
    "    # محاسبه مجموع وزن‌دار: z = w1*x1 + w2*x2 + b\n",
    "    z = weights_hidden[i][0] * inputs[0] + weights_hidden[i][1] * inputs[1] + bias_hidden[i]\n",
    "    a = sigmoid(z)  # اعمال تابع فعال‌ساز\n",
    "    hidden_outputs.append(a)  # ذخیره خروجی هر نرون\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اینجا، هر نرون لایه پنهان مقدار z خودش را محاسبه کرده و آن را از تابع سیگموید عبور می‌دهد تا خروجی خودش را تولید کند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# قدم 5: وزن‌ها و بایاس برای لایه خروجی (Output Layer)\n",
    "weights_output = [0.3, 0.5]  # برای دو نرون لایه پنهان\n",
    "bias_output = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "خروجی فقط یک نرون دارد که از خروجی‌های لایه پنهان استفاده می‌کند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output of the network: 0.6840037798198644\n"
     ]
    }
   ],
   "source": [
    "# قدم 6: محاسبه خروجی نهایی شبکه (Forward Propagation - Output Layer)\n",
    "z_output = weights_output[0] * hidden_outputs[0] + weights_output[1] * hidden_outputs[1] + bias_output\n",
    "output = sigmoid(z_output)  # اعمال تابع فعال‌ساز برای خروجی نهایی\n",
    "\n",
    "# نمایش خروجی نهایی\n",
    "print(\"Final output of the network:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این مقدار، خروجی نهایی شبکه است، یعنی پیش‌بینی مدل ما با وزن‌ها و بایاس فعلی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml77](./images/mln77.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml78](./images/mln78.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml79](./images/mln79.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml80](./images/mln80.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml87](./images/mln87.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml81](./images/mln81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml82](./images/mln82.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml83](./images/mln83.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml84](./images/mln84.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml85](./images/mln85.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml86](./images/mln86.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml88](./images/mln88.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml89](./images/mln89.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln90](./images/mln90.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln91](./images/mln91.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln92](./images/mln92.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln93](./images/mln93.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln94](./images/mln94.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln95](./images/mln95.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln96](./images/mln96.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln97](./images/mln97.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln98](./images/mln98.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln99](./images/mln99.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln100](./images/mln100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln101](./images/mln101.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln102](./images/mln102.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln103](./images/mln103.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln104](./images/mln104.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln105](./images/mln105.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln106](./images/mln106.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln107](./images/mln107.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln108](./images/mln108.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln109](./images/mln109.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln110](./images/mln110.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln111](./images/mln111.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln112](./images/mln112.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mln113](./images/mln113.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# پروژه‌ی  دیپ‌لرنینگ با استفاده از دیتاست MNIST\n",
    "\n",
    "در این پروژه قصد داریم از صفر تا صد مدل‌سازی یک شبکه‌ی عصبی عمیق (Deep Neural Network) برای دسته‌بندی دست‌نوشته‌های دیتاست MNIST را پیاده‌سازی کنیم. این کد  با استفاده از کتابخانه‌ی TensorFlow/Keras نوشته شده.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "\n",
    "## فهرست مطالب\n",
    "1. [مقدمه](#مقدمه)\n",
    "2. [نصب و وارد کردن کتابخانه‌ها](#نصب-و-وارد-کردن-کتابخانه‌ها)\n",
    "3. [بارگذاری و پیش‌پردازش دیتاست MNIST](#بارگذاری-و-پیش‌پردازش-دیتاست-mnist)\n",
    "4. [تعریف معماری مدل (شبکه عصبی)](#تعریف-معماری-مدل-شبکه-عصبی)\n",
    "   - [لایه‌های Dense و Flatten](#لایه‌های-dense-و-flatten)\n",
    "   - [تابع فعال‌سازی (Activation Functions)](#تابع-فعال‌سازی-activation-functions)\n",
    "   - [Batch Normalization و Dropout](#batch-normalization-و-dropout)\n",
    "5. [انتخاب Loss Function و توضیح Cross-Entropy](#انتخاب-loss-function-و-توضیح-cross-entropy)\n",
    "6. [انتخاب Optimizer و توضیح Gradient Descent و Learning Rate](#انتخاب-optimizer-و-توضیح-gradient-descent-و-learning-rate)\n",
    "   - [SGD (Stochastic Gradient Descent)](#sgd-stochastic-gradient-descent)\n",
    "   - [Adam Optimizer](#adam-optimizer)\n",
    "   - [Scheduler نرخ یادگیری (Learning Rate Scheduler)](#scheduler-نرخ-یادگیری-learning-rate-scheduler)\n",
    "7. [کامپایل مدل](#کامپایل-مدل)\n",
    "8. [آموزش مدل و نمایش نتایج](#آموزش-مدل-و-نمایش-نتایج)\n",
    "   - [توضیح فراخوانی متد fit](#توضیح-فراخوانی-متد-fit)\n",
    "   - [نمایش منحنی‌های Loss و Accuracy](#نمایش-منحنی‌های-loss-و-accuracy)\n",
    "9. [ارزیابی نهایی مدل](#ارزیابی-نهایی-مدل)\n",
    "10. [پیش‌بینی روی تصاویر جدید](#پیش‌بینی-روی-تصاویر-جدید)\n",
    "11. [جمع‌بندی](#جمع‌بندی)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## مقدمه\n",
    "\n",
    "در این پروژه می‌خواهیم یک مدل ساده اما جامع برای دسته‌بندی تصاویر دست‌نوشته‌ی ارقامی که از ۰ تا ۹ هستند، بسازیم. دیتاست MNIST شامل ۶۰٬۰۰۰ نمونه‌ی آموزشی و ۱۰٬۰۰۰ نمونه‌ی تست است که هر نمونه یک تصویر ۲۸×۲۸ پیکسل به صورت خاکستری (grayscale) می‌باشد. هدف ما این است که مدلی طراحی کنیم که بتواند عدد نوشته شده در تصویر را به درستی شناسایی کند.\n",
    "\n",
    "> **نکته:** برای ساده بودن کد، از **TensorFlow 2.x** و لایه‌های **Keras** استفاده کرده‌ایم.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## نصب و وارد کردن کتابخانه‌ها\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "تابع to_categorical برای تبدیل برچسب‌های عددی (مثل 0 تا 9) به بردارهای One-Hot استفاده می‌شود (برای محاسبه‌ی Cross-Entropy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "## بارگذاری و پیش‌پردازش دیتاست MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 1. بارگذاری دیتاست MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "بارگذاری دیتاست: با تابع mnist.load_data() دو مجموعه‌ی آموزشی و تست را دریافت می‌کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 2. نرمال‌سازی تصاویر: تبدیل پیکسل‌ها به بازه [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "نرمال‌سازی پیکسل‌ها: مقادیر اولیه در بازه‌ی [0, 255] هستند؛ برای کارایی بهتر شبکه و همگرایی سریع‌تر باید آن‌ها را به بازه‌ی [0, 1] مقیاس‌دهی کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 3. اضافه کردن بعد کانال (برای انطباق با لایه‌های Conv اگر نیاز بود؛ در این پروژه از لایه Dense استفاده می‌کنیم)\n",
    "#    در اینجا تصاویر به صورت (28, 28) هستند؛ برخی مدل‌های CNN نیاز به شکل (28, 28, 1) دارند.\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test  = x_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "reshape کردن تصاویر: چون در این مثال از شبکه‌ی کاملاً متصل (Fully Connected) استفاده می‌کنیم، باید تصاویر را به بردار ۷۸۴ بعدی تبدیل کنیم. (۲۸ × ۲۸ = ۷۸۴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شکل مجموعه‌ی آموزشی: (60000, 784) (60000, 10)\n",
      "شکل مجموعه‌ی تست: (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 4. تبدیل برچسب‌ها به One-Hot\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test  = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"شکل مجموعه‌ی آموزشی:\", x_train.shape, y_train.shape)\n",
    "print(\"شکل مجموعه‌ی تست:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "One-Hot Encoding: برچسب‌ها (اعداد ۰ تا ۹) را به بردارهای صفر و یک تبدیل می‌کنیم تا بتوانیم از Cross-Entropy استفاده کنیم. تعداد کلاس‌ها ۱۰ است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "## تعریف معماری مدل (شبکه عصبی)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    #    - input_shape=(784,) به این معناست که ورودی یک بردار ۷۸۴ بعدی است.\n",
    "    #    - فعال‌سازی: ReLU\n",
    "    layers.Dense(512, input_shape=(784,), activation='relu', name='dense_1'),\n",
    "\n",
    "\n",
    "    # 2. Dropout با نرخ 0.5\n",
    "    #    - وظیفه: در هر بار آموزش، تصادفی 50٪ نورون‌ها را غیرفعال می‌کند.\n",
    "    #    - مزایا: کاهش Overfitting (بیش‌برازش)، افزایش عمومی‌سازی مدل.\n",
    "    layers.Dropout(0.5, name='dropout_1'),\n",
    "\n",
    "    # 3. لایه‌ی پنهان دوم: Dense با 256 نورون و فعال‌سازی ReLU\n",
    "    layers.Dense(256, activation='relu', name='dense_2'),\n",
    "    layers.BatchNormalization(name='batch_norm_2'),\n",
    "    layers.Dropout(0.5, name='dropout_2'),\n",
    "\n",
    "    # 4. لایه‌ی خروجی: Dense با 10 نورون (تعداد کلاس‌ها) و فعال‌سازی Softmax\n",
    "    layers.Dense(10, activation='softmax', name='output_layer'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "\n",
    "   لایه‌ی Dense اول (dense_1)\n",
    "\n",
    "\n",
    "512 نورون دارد.\n",
    "   \n",
    "   input_shape=(784,) یعنی ورودی یک بردار ۷۸۴ بعدی (تعداد پیکسل‌های یک تصویر ۲۸×۲۸).\n",
    "   \n",
    "   Activation Function: ReLU\n",
    "\n",
    "مزایا: محاسبه ساده و سریع، کمک به رفع مشکل Vanishing Gradient (گرادیان‌های خیلی کوچک در لایه‌های عمیق).\n",
    "\n",
    "معایب: در صورتی که ورودی منفی باشد، گرادیان صفر می‌شود (نوریون از کار می‌افتد یا اصطلاحاً “Dead Neuron”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "Dropout (dropout_1)\n",
    "\n",
    "   هنگام آموزش، به‌طور تصادفی ۵۰٪ نورون‌های لایه‌ی قبلی را “خاموش” می‌کند.\n",
    "\n",
    "   هدف: جلوگیری از وابستگی بیش از حد نورون‌ها به یکدیگر (Co-adaptation) و در نتیجه کاهش Overfitting.\n",
    "\n",
    "   در فاز ارزیابی (ارزیابی و پیش‌بینی)، Dropout غیرفعال می‌شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "لایه‌ی Dense دوم (dense_2)\n",
    "\n",
    "   مثل لایه‌ی اول، اما با ۲۵۶ نورون.\n",
    "\n",
    "   فعال‌سازی ReLU.\n",
    "\n",
    "   سپس دوباره Batch Normalization و Dropout روی آن اعمال می‌شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "لایه‌ی خروجی (output_layer)\n",
    "\n",
    "   دارای ۱۰ نورون (به‌ازای هر کلاس یک نورون).\n",
    "\n",
    "   Activation Function: Softmax\n",
    "\n",
    "   تبدیل خروجی‌ها به احتمال هر کلاس.\n",
    "\n",
    "\n",
    "   خروجی: برداری از احتمالات که جمع آن برابر ۱ است.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "## کامپایل مدل\n",
    "\n",
    "پس از تعریف معماری شبکه، باید مدل را کامپایل کنیم. در این مرحله، Loss Function، Optimizer و Metrics (معیارهای ارزیابی) را مشخص می‌کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# انتخاب Optimizer: Adam\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# کامپایل مدل\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "  optimizer=optimizer: از Adam با نرخ یادگیری 0.001 استفاده می‌کنیم.\n",
    "\n",
    " *  یکی از پرکاربردترین Optimizerهای امروز.\n",
    "\n",
    "  * ترکیبی از Adaptive Gradient Algorithm (AdaGrad) و RMSProp به همراه مومنتوم.\n",
    "\n",
    "  * نیازی به تنظیم بیش از حد Learning Rate ندارد (اما معمولاً مقدار پیش‌فرض 0.001 به خوبی کار می‌کند).\n",
    "\n",
    "\n",
    "loss='categorical_crossentropy': برای دسته‌بندی چندکلاسه.\n",
    "\n",
    "metrics=['accuracy']: دقت (Accuracy) را به عنوان معیار اصلی برای ارزیابی مدل در طول آموزش و تست درنظر می‌گیریم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "## آموزش مدل و نمایش نتایج\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EarlyStopping: اگر مدل در چند epoch اعتبارسنجی بهبود نداشت، زودتر متوقف شود.\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# 2. ReduceLROnPlateau: کاهش نرخ یادگیری اگر val_loss بهبود نداشت.\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "EarlyStopping\n",
    "\n",
    "   تابع: اگر بعد از چند دوره (epoch) مقدار val_loss کاهش نیابد (بهبود نداشته باشد)، آموزش را متوقف می‌کند.\n",
    "\n",
    "   patience=5: حداکثر ۵ epoch منتظر می‌ماند تا بهبود صورت بگیرد.\n",
    "\n",
    "   restore_best_weights=True: پس از پایان آموزش، بهترین وزن‌های ثبت‌شده را بر می‌گرداند.\n",
    "\n",
    "ReduceLROnPlateau\n",
    "\n",
    "   اگر val_loss برای چند epoch بهبود نداشت، نرخ یادگیری را تا حد معینی کاهش می‌دهد (factor=0.5 یعنی نصف کردن نرخ یادگیری).\n",
    "\n",
    "   min_lr=1e-6: حداقل نرخ یادگیری.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# حداکثر 5 دوره (epoch)\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# اندازه دسته (mini-batch) برابر 128\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 10٪ داده‌های آموزشی برای اعتبارسنجی (Validation)\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# نمایش خلاصه در هر epoch\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\test jupiter\\rise_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\test jupiter\\rise_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:2079\u001b[0m, in \u001b[0;36msignbit\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2074\u001b[0m     x \u001b[38;5;241m=\u001b[39m cast(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mless(\n\u001b[0;32m   2076\u001b[0m         tf\u001b[38;5;241m.\u001b[39mbitwise\u001b[38;5;241m.\u001b[39mbitwise_and(\n\u001b[0;32m   2077\u001b[0m             tf\u001b[38;5;241m.\u001b[39mbitcast(x, tf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[0;32m   2078\u001b[0m             \u001b[38;5;66;03m# tf.float32 sign bit\u001b[39;00m\n\u001b[1;32m-> 2079\u001b[0m             \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0x80000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2080\u001b[0m         ),\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2082\u001b[0m     )\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,               # حداکثر 5 دوره (epoch)\n",
    "    batch_size=128,          # اندازه دسته (mini-batch) برابر 128\n",
    "    validation_split=0.1,    # 10٪ داده‌های آموزشی برای اعتبارسنجی (Validation)\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=2                # نمایش خلاصه در هر epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "x_train, y_train: داده‌های آموزشی.\n",
    "\n",
    "epochs=30: تعداد حداکثر دوره‌ها. (ممکن است پیش از 5 به‌دلیل EarlyStopping متوقف شود.)\n",
    "\n",
    "batch_size=128: هر بار 128 نمونه برای به‌روزرسانی گرادیان استفاده می‌شود.\n",
    "\n",
    "validation_split=0.1: ۱۰٪ از داده‌های آموزشی به عنوان داده‌ی اعتبارسنجی جدا می‌شود.\n",
    "\n",
    "callbacks=[...]: لیستی از Callbackهای تعریف‌شده (EarlyStopping و LR Scheduler).\n",
    "\n",
    "verbose=2: نمایش اطلاعات خلاصه‌ی هر epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 1. دسترسی به تاریخچه (History) آموزش\n",
    "history_dict = history.history\n",
    "\n",
    "# 2. استخراج مقادیر\n",
    "train_loss = history_dict['loss']\n",
    "val_loss   = history_dict['val_loss']\n",
    "train_acc  = history_dict['accuracy']\n",
    "val_acc    = history_dict['val_accuracy']\n",
    "epochs     = range(1, len(train_loss) + 1)\n",
    "\n",
    "# 3. رسم منحنی Loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r--', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 4. رسم منحنی Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r--', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "\n",
    "از history.history برای دسترسی به مقادیر Loss و Accuracy در هر epoch استفاده می‌کنیم.\n",
    "\n",
    "سپس دو نمودار کنار هم رسم می‌کنیم:\n",
    "\n",
    "   منحنی Loss: مقایسه Loss داده‌های آموزشی و اعتبارسنجی.\n",
    "\n",
    "   منحنی Accuracy: مقایسه دقت (Accuracy) داده‌های آموزشی و اعتبارسنجی.\n",
    "\n",
    "این نمودارها به ما کمک می‌کنند تا تشخیص دهیم آیا مدل در حال بیش‌برازش (overfitting) یا کم‌برازش (underfitting) است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\test jupiter\\rise_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\test jupiter\\rise_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:2079\u001b[0m, in \u001b[0;36msignbit\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2074\u001b[0m     x \u001b[38;5;241m=\u001b[39m cast(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mless(\n\u001b[0;32m   2076\u001b[0m         tf\u001b[38;5;241m.\u001b[39mbitwise\u001b[38;5;241m.\u001b[39mbitwise_and(\n\u001b[0;32m   2077\u001b[0m             tf\u001b[38;5;241m.\u001b[39mbitcast(x, tf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[0;32m   2078\u001b[0m             \u001b[38;5;66;03m# tf.float32 sign bit\u001b[39;00m\n\u001b[1;32m-> 2079\u001b[0m             \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0x80000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2080\u001b[0m         ),\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2082\u001b[0m     )\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "model.evaluate داده‌های تست را می‌گیرد و Loss و Accuracy را برمی‌گرداند.\n",
    "\n",
    "مقادیر به‌دست‌آمده نشان‌دهنده‌ی عملکرد واقعی مدل روی داده‌هایی هستند که تا کنون ندیده است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. انتخاب چند تصویر نمونه از x_test\n",
    "num_samples = 5\n",
    "random_indices = np.random.choice(len(x_test), num_samples, replace=False)\n",
    "sample_images = x_test[random_indices]\n",
    "sample_labels = y_test[random_indices]\n",
    "\n",
    "# 2. پیش‌بینی برای نمونه‌ها (احتمالات)\n",
    "pred_probs = model.predict(sample_images)\n",
    "# پیدا کردن کلاس با بیشترین احتمال\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "true_classes = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "# 3. نمایش تصاویر همراه با برچسب واقعی و پیش‌بینی‌شده\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1, num_samples, i+1)\n",
    "    image = sample_images[i].reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"True: {true_classes[i]}\\nPred: {pred_classes[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div dir=\"rtl\" markdown=\"1\">\n",
    "\n",
    "با np.random.choice پنج ایندکس تصادفی از داده‌های تست انتخاب می‌کنیم.\n",
    "\n",
    "برای هر تصویر:\n",
    "\n",
    "   مدل خروجی احتمالاتی (Softmax) را می‌دهد.\n",
    "\n",
    "   با np.argmax کلاس با بیشترین احتمال را استخراج می‌کنیم.\n",
    "\n",
    "سپس با matplotlib تصاویر را به همراه برچسب واقعی و پیش‌بینی شده به نمایش می‌گذاریم."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
